[{"content":"I wanted to run real applications—not toy projects, but actual software I\u0026rsquo;d use daily. Finance tracking. Job search management. Jupyter notebooks. AI observability for my Claude Code sessions.\nBut I also wanted to do it right. Not \u0026ldquo;throw it in a Docker container and hope for the best\u0026rdquo; right. Actually right:\nEncrypted service-to-service communication Centralized secrets management Automatic failover and recovery Observable, debuggable, maintainable The catch? I didn\u0026rsquo;t want to pay $50-200/month for a \u0026ldquo;real\u0026rdquo; Kubernetes cluster.\nThe Solution Oracle Cloud\u0026rsquo;s Always Free tier includes an ARM instance with 4 OCPUs and 24GB RAM. That\u0026rsquo;s not a typo—24 gigabytes of memory, free forever.\nI spent a day turning it into oracle-mesh: a complete application platform running Kubernetes, Linkerd service mesh, Traefik ingress, HashiCorp Vault, and four production applications.\nTotal monthly cost: $0.\nWhat\u0026rsquo;s Running The Infrastructure Layer ┌ │ │ │ │ │ │ │ │ └ ─ ─ ─ ─ ─ K ┌ │ │ └ ─ ─ I ─ ─ ─ ─ N ─ L ─ ─ ─ D ─ i ( ─ ─ ─ ─ n m ─ ─ ─ ( ─ k e ─ ─ ─ K ─ e s ─ ─ ─ u ─ r h ─ ─ ─ b ─ d ) ─ ─ ─ e ─ ─ ─ ─ r ─ ─ ─ ─ n ┐ │ │ ┘ ─ ─ e ─ ─ t ─ ─ e ┌ │ │ └ ─ ─ s ─ ( ─ ─ ─ ) ─ T i ─ ─ ─ ─ r n ─ ─ ─ ─ a g ─ ─ ─ ─ e r ─ ─ ─ ─ f e ─ ─ ─ ─ i s ─ ─ ─ ─ k s ─ ─ ─ ─ ) ─ ─ ─ ─ ─ ─ ─ ┐ │ │ ┘ ─ ─ ─ ─ ─ ─ ┌ │ │ └ ─ ─ ─ ( ─ ─ ─ ─ s ─ ─ ─ ─ V e ─ ─ ─ ─ a c ─ ─ ─ ─ u r ─ ─ ─ ─ l e ─ ─ ─ ─ t t ─ ─ ─ ─ s ─ ─ ─ ─ ) ─ ─ ─ ─ ─ ─ ─ ┐ │ │ ┘ ─ ─ ─ ─ ─ ─ ┌ │ │ │ ─ ─ ─ P │ └ ─ ─ ─ o C ─ ─ ─ ─ s R M l ─ ─ ─ ─ t e i i ─ ─ ─ ─ g d n c ─ ─ ─ ─ r i I k ─ ─ ─ ─ e s O H ─ ─ ─ ─ S o ─ ─ ─ ─ Q u ─ ─ ─ ─ L s ─ ─ ─ ┐ │ │ │ e ─ ─ ─ │ ┘ ─ ─ ─ ─ ─ ─ │ │ │ │ ─ ─ │ │ ─ ┐ │ │ ┘ Linkerd wraps every pod with a sidecar proxy. All traffic between services is mTLS-encrypted automatically. I didn\u0026rsquo;t write a single line of TLS code—the mesh handles it.\nTraefik routes external traffic to the right services. Everything lives under path prefixes (/budget/, /jobs/, /jupyter/), so I only need one hostname.\nVault stores every secret—database passwords, API keys, tokens. Applications never see credentials in environment variables. They\u0026rsquo;re injected at runtime from Vault.\nThe Data Layer PostgreSQL with four isolated databases (finance, jobsearch, langfuse, jupyter) Redis for caching and queues MinIO for S3-compatible object storage ClickHouse for analytics and time-series data All credentials are Vault-managed. When I deploy a new app, I create a database, store the password in Vault, and the app gets a connection string. No credentials in git, ever.\nThe Applications Actual Budget — A local-first personal finance app. Think YNAB but self-hosted. Every transaction, every budget, stored on my infrastructure.\nPlanka — A Trello-like kanban board I use for job search tracking. Cards for applications, columns for stages (Applied, Interviewing, Offer, Rejected). Uses the PostgreSQL database directly.\nJupyterLab — Data science notebooks with direct access to all my databases. I can query my finance data, job search history, or AI traces from a single notebook.\nLangfuse — This is the interesting one.\nAI Observability: Why Langfuse Matters I use Claude Code daily. It writes code, runs commands, manages files. But until now, those interactions were ephemeral—I couldn\u0026rsquo;t see what prompts were sent, how many tokens were used, or debug why something went wrong.\nLangfuse changes that.\nIt\u0026rsquo;s an open-source observability platform for LLM applications. Every Claude Code session can be traced:\nWhat prompts were sent What responses came back Token counts and latency Tool calls and their results The entire conversation becomes observable, searchable, and debuggable.\nWhy Self-Host? Langfuse has a cloud offering, but I wanted the data on my infrastructure. AI prompts often contain proprietary code, business logic, or sensitive context. Self-hosting means:\nComplete data ownership No usage limits Integration with my existing database infrastructure The satisfaction of running it myself The Langfuse stack requires PostgreSQL (have it), Redis (have it), MinIO (have it), and ClickHouse (added it). The platform I\u0026rsquo;d already built made adding AI observability trivial.\nThe Hard Parts Linkerd Needs Gateway API CRDs The Linkerd installation failed immediately:\nT h e G a t e w a y A P I C R D s m u s t b e i n s t a l l e d p r i o r t o i n s t a l l i n g L i n k e r d . This is a relatively new requirement (2024+). The fix is simple—install the CRDs first—but it wasn\u0026rsquo;t in any of the quick-start guides I\u0026rsquo;d read.\nVault Hates Read-Only ConfigMaps Vault\u0026rsquo;s Docker image has an entrypoint script that tries to chown the config directory. Kubernetes ConfigMaps are always read-only. The pod crash-looped until I bypassed the entrypoint:\ncommand: [\u0026#34;/bin/vault\u0026#34;] args: - server - -config=/vault/config/vault.hcl Tailscale MagicDNS Doesn\u0026rsquo;t Do Subdomains I originally planned to use demo.monitoring-arm.ts.net, vault.monitoring-arm.ts.net, etc. MagicDNS doesn\u0026rsquo;t resolve subdomains—only exact hostnames registered in the tailnet.\nThe fix was path-based routing: everything at monitoring-arm/demo/, monitoring-arm/vault/, etc. This required Traefik\u0026rsquo;s stripPrefix middleware to remove the path prefix before forwarding to backends.\nPostgreSQL 15+ Changed Default Permissions When Planka tried to create its database tables:\np e r m i s s i o n d e n i e d f o r s c h e m a p u b l i c PostgreSQL 15 changed the default behavior—regular users can no longer create objects in the public schema. I had to explicitly grant permissions:\nGRANT ALL ON SCHEMA public TO planka_app; ClickHouse Single-Node vs Cluster Langfuse\u0026rsquo;s migrations assume a ClickHouse cluster with Zookeeper. My single-node setup doesn\u0026rsquo;t have Zookeeper. The fix:\nenv: - name: CLICKHOUSE_CLUSTER_ENABLED value: \u0026#34;false\u0026#34; What I Learned Service Meshes Are Worth It I was skeptical of Linkerd\u0026rsquo;s value for a personal project. But having automatic mTLS between every service is genuinely useful. I don\u0026rsquo;t think about encryption—it just happens. The observability (which service is talking to which, success rates, latency percentiles) is a bonus.\nVault Is Overkill (But I\u0026rsquo;m Glad I Did It) For a personal project, Kubernetes secrets would be fine. But using Vault taught me patterns I\u0026rsquo;ll use professionally:\nSecrets have versions Secrets can be rotated without redeploying apps Access can be audited The same patterns work at any scale KIND Is Production-Ready (For Personal Use) KIND (Kubernetes IN Docker) is usually positioned as a development tool. But for a single-node personal cluster, it works great. The cluster survives host reboots. Persistent volumes work. The only limitation is no multi-node HA—which I don\u0026rsquo;t need.\nFree Tier ARM Is Seriously Capable 24GB of RAM is substantial. After deploying 21 pods across all tiers, I\u0026rsquo;m using 3.9GB. That\u0026rsquo;s 84% headroom. I could add several more applications before needing to optimize.\nThe Numbers Metric Value Total pods 21 Applications 7 (demo, vault, minio, budget, jobs, jupyter, langfuse) Databases 4 PostgreSQL + 1 ClickHouse RAM used 3.9 GB / 24 GB Disk used 18 GB / 45 GB Monthly cost $0 mTLS coverage 100% Try It Yourself The entire setup is documented in my oracle repository:\nDesign document: Full architecture and decision rationale Phase guides: Step-by-step deployment instructions Lessons learned: Every gotcha I hit and how to avoid them Manifests: All Kubernetes YAML, ready to apply The core insight: enterprise patterns aren\u0026rsquo;t just for enterprises. Service mesh, secrets management, and observability are tools that improve security and reliability at any scale. The barrier isn\u0026rsquo;t capability—it\u0026rsquo;s knowing how to start.\nOracle\u0026rsquo;s free tier removes the cost barrier. The documentation removes the knowledge barrier. What\u0026rsquo;s left is just doing it.\nWhat\u0026rsquo;s Next The platform is complete, but it\u0026rsquo;s also a foundation. Next steps I\u0026rsquo;m considering:\nPrometheus + Grafana for metrics visualization Loki for centralized logging ArgoCD for GitOps deployments n8n for workflow automation Each addition follows the same pattern: store credentials in Vault, deploy to the mesh, expose via Traefik. The hard work is done.\nFinal Thoughts A year ago, running this infrastructure would have cost $100-300/month and required significant DevOps expertise. Today, it\u0026rsquo;s free and documented.\nThe tools have matured. The free tiers have expanded. The documentation has improved. What used to require a team now requires an afternoon.\nIf you\u0026rsquo;ve been waiting to learn Kubernetes, service mesh, or infrastructure-as-code—stop waiting. The barrier is lower than you think. And the skills transfer directly to professional work.\nI built a $0/month enterprise platform. You can too.\noracle-mesh is open source. Find the documentation, manifests, and guides in the oracle repository.\n","permalink":"https://jcaldwell-labs.github.io/blog/2026-02-04-oracle-mesh-complete/","summary":"\u003cp\u003eI wanted to run real applications—not toy projects, but actual software I\u0026rsquo;d use daily. Finance tracking. Job search management. Jupyter notebooks. AI observability for my Claude Code sessions.\u003c/p\u003e\n\u003cp\u003eBut I also wanted to do it \u003cem\u003eright\u003c/em\u003e. Not \u0026ldquo;throw it in a Docker container and hope for the best\u0026rdquo; right. Actually right:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEncrypted service-to-service communication\u003c/li\u003e\n\u003cli\u003eCentralized secrets management\u003c/li\u003e\n\u003cli\u003eAutomatic failover and recovery\u003c/li\u003e\n\u003cli\u003eObservable, debuggable, maintainable\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe catch? I didn\u0026rsquo;t want to pay $50-200/month for a \u0026ldquo;real\u0026rdquo; Kubernetes cluster.\u003c/p\u003e","title":"I Built a $0/Month Enterprise Platform (And You Can Too)"},{"content":"The Invisible Systems That Run Your Business Every modern business runs on invisible systems.\nWhen you swipe your badge to enter the building, a system checks your credentials. When you submit an expense report, a system routes it for approval. When you check inventory, a system queries a database somewhere. When a customer places an order, dozens of systems coordinate to make it happen.\nYou don\u0026rsquo;t think about these systems. They just work. Someone in IT set them up, maintains them, and makes sure they\u0026rsquo;re secure. The systems run in the background while you focus on your actual job.\nAI tools are becoming another one of these invisible systems.\nAnd just like every other business system, they need proper infrastructure—security, monitoring, and management. That\u0026rsquo;s what this article is about.\nWhat\u0026rsquo;s Actually Happening When You Use AI at Work Let\u0026rsquo;s say you\u0026rsquo;re using an AI assistant to help draft emails, analyze spreadsheets, or write reports. Here\u0026rsquo;s what\u0026rsquo;s actually happening behind the scenes:\nYou type a question or request Your text gets sent to a server (usually in a data center somewhere) The AI processes your request (this is the \u0026ldquo;thinking\u0026rdquo; part) A response comes back to you Simple enough. But here\u0026rsquo;s what most people don\u0026rsquo;t realize:\nThat server might be owned by a third party Your question—which might include company data—travels over the internet There\u0026rsquo;s usually no record of what you asked or what the AI answered If something goes wrong, nobody knows why For personal use, this is fine. For business use, it\u0026rsquo;s a problem.\nWhy Businesses Need AI Infrastructure Think about how your company handles other sensitive systems.\nEmail doesn\u0026rsquo;t run on someone\u0026rsquo;s personal Gmail. Your company has its own email servers (or pays Microsoft/Google for business accounts) with security, backups, and audit logs.\nFinancial data doesn\u0026rsquo;t live in random spreadsheets. It\u0026rsquo;s in accounting systems with access controls, approval workflows, and audit trails.\nCustomer information doesn\u0026rsquo;t float around unprotected. There are databases with encryption, backups, and compliance certifications.\nAI should work the same way. But most businesses are using AI tools with none of these protections in place.\nThe Three Things Every Business AI System Needs 1. Security (Who Can Access What) When an employee uses AI to analyze sales data, that data shouldn\u0026rsquo;t be accessible to anyone else. When a manager uses AI to draft performance reviews, those drafts need to be private.\nThe infrastructure solution: Systems that encrypt data in transit and at rest, control who can access what, and keep secrets (like passwords and API keys) locked away from prying eyes.\n2. Observability (What\u0026rsquo;s Actually Happening) If your AI assistant suddenly starts giving bad advice, how would you know? If it\u0026rsquo;s costing twice as much as last month, who would notice? If an employee is using it to process data they shouldn\u0026rsquo;t have access to, where\u0026rsquo;s the audit trail?\nThe infrastructure solution: Logging and monitoring that tracks every AI interaction—what was asked, what was answered, how long it took, and how much it cost.\n3. Reliability (It Works When You Need It) Your email doesn\u0026rsquo;t go down because too many people sent messages at once. Your accounting system doesn\u0026rsquo;t crash at the end of the quarter when everyone\u0026rsquo;s filing reports. Business systems are built to handle load and recover from failures.\nThe infrastructure solution: Redundancy, automatic recovery, and proper resource management so the AI tools work when your team needs them.\nWhat We Built (In Plain English) I built a system that provides all three of these things. Here\u0026rsquo;s what it does, without the technical jargon:\nSecurity Layer What it does: Every piece of data that moves between systems is encrypted. Passwords and API keys are stored in a digital vault that requires authentication to access. Nothing is hardcoded or sitting in plain text.\nWhy it matters: If someone intercepts network traffic, they see gibberish. If someone breaks into one system, they can\u0026rsquo;t use it to access others. The same security practices that Fortune 500 companies use, running on a single server.\nMonitoring Layer What it does: Every AI interaction is logged. You can see what questions were asked, what answers came back, how long it took, and how much it cost. Think of it like a call log for your AI assistant.\nWhy it matters: You can debug problems (\u0026ldquo;Why did the AI give bad advice last Tuesday?\u0026rdquo;). You can track costs (\u0026ldquo;We\u0026rsquo;re spending $X per month on AI, and here\u0026rsquo;s what we\u0026rsquo;re using it for\u0026rdquo;). You can audit usage (\u0026ldquo;Here\u0026rsquo;s every time someone used AI to process customer data\u0026rdquo;).\nApplication Layer What it does: Runs actual useful applications—financial tracking, project management, data analysis notebooks, and the AI monitoring dashboard itself.\nWhy it matters: This isn\u0026rsquo;t theoretical infrastructure. It\u0026rsquo;s running real software that people use every day.\nA Real Example: AI Observability Let me make this concrete with the monitoring piece, because it\u0026rsquo;s the part most relevant to AI.\nI use an AI coding assistant daily. It reads my files, writes code, runs commands. Before this system, those interactions were invisible. The AI would do something, I\u0026rsquo;d see the result, and that was it.\nNow, every interaction is logged to a dashboard:\nWhat I asked: The exact prompt I typed What it did: Every file it read, every command it ran What it answered: The full response How long it took: Response times for each step What it cost: Token usage (how AI pricing works) If the AI makes a mistake, I can go back and see exactly what happened. If costs spike, I can see why. If I want to improve how I use it, I have data to analyze.\nThis is the same visibility that businesses have for their other systems. Your CRM tracks every customer interaction. Your accounting system logs every transaction. Your email system keeps records. AI should be no different.\nWhy This Matters for Non-Technical Professionals You might be thinking: \u0026ldquo;I\u0026rsquo;m an accountant / lawyer / project manager / [insert profession]. Why should I care about AI infrastructure?\u0026rdquo;\nHere\u0026rsquo;s why:\nAI Is Becoming Part of Your Job Whether you\u0026rsquo;re using it yet or not, AI tools are entering every profession. Lawyers use AI for document review. Accountants use AI for analysis. Project managers use AI for planning. This isn\u0026rsquo;t future speculation—it\u0026rsquo;s happening now.\nYour Company Will Need to Manage It Just like your company had to figure out email, then mobile devices, then cloud storage, they\u0026rsquo;ll have to figure out AI. The companies that do it well will have:\nSecurity controls (so sensitive data stays protected) Usage visibility (so they know what\u0026rsquo;s happening) Cost management (so AI doesn\u0026rsquo;t become an uncontrolled expense) The Infrastructure Exists The good news: this isn\u0026rsquo;t unsolved. The same patterns that work for databases, web applications, and other business systems work for AI. It just needs to be set up properly.\nThe Cost Question \u0026ldquo;This sounds expensive.\u0026rdquo;\nHere\u0026rsquo;s the surprising part: the system I built runs on free cloud infrastructure. Oracle offers a free tier that includes a server with 24GB of memory—enough to run all of this.\nThe software is open source:\nKubernetes (container orchestration) — free Linkerd (security mesh) — free Vault (secrets management) — free Langfuse (AI monitoring) — free The total monthly cost: $0.\nThe catch is that someone needs to know how to set it up and maintain it. That\u0026rsquo;s a real cost—either in time (if someone learns it) or money (if you hire someone). But the infrastructure itself is free.\nWhat This Looks Like Day-to-Day Once it\u0026rsquo;s running, you don\u0026rsquo;t think about it. Just like you don\u0026rsquo;t think about your email server.\nFor end users: Nothing changes. You use AI tools the same way you always did.\nFor IT/admins: There\u0026rsquo;s a dashboard showing system health, usage patterns, and costs. If something breaks, there are logs to investigate. If someone asks \u0026ldquo;how much are we spending on AI?\u0026rdquo;, there\u0026rsquo;s an answer.\nFor leadership: You can make informed decisions. \u0026ldquo;Our team used AI for 500 hours last month, primarily for document drafting and data analysis. It cost $X and saved approximately Y hours of manual work.\u0026rdquo;\nThe Bottom Line AI tools are becoming as fundamental as email and spreadsheets. Every company will use them. The question is whether they\u0026rsquo;ll use them with proper infrastructure or not.\nProper infrastructure means:\nSecurity: Data is protected Visibility: Usage is tracked and auditable Reliability: Systems work when you need them This isn\u0026rsquo;t optional for businesses. It\u0026rsquo;s the same standard we apply to every other system that handles company data.\nThe technology exists. It\u0026rsquo;s mature. It\u0026rsquo;s even free. What\u0026rsquo;s needed is awareness that AI infrastructure is a thing that should exist, and the will to set it up properly.\nWhether you\u0026rsquo;re an IT professional evaluating options, a manager trying to understand what your team needs, or just someone who wants to understand the landscape—this is what AI infrastructure looks like. It\u0026rsquo;s not magic. It\u0026rsquo;s just good systems engineering applied to a new category of tools.\nGlossary (If You Want to Go Deeper) Kubernetes: Software that manages applications running in containers. Think of it as an automated system administrator that keeps everything running.\nService Mesh (Linkerd): A layer that handles communication between applications. It encrypts traffic and tracks what\u0026rsquo;s talking to what.\nSecrets Management (Vault): A secure storage system for passwords, API keys, and other sensitive credentials. Applications request secrets when they need them rather than storing them directly.\nObservability (Langfuse): Tools for understanding what\u0026rsquo;s happening inside a system. For AI, this means logging prompts, responses, timing, and costs.\nmTLS: Mutual TLS. A security protocol where both sides of a connection verify each other\u0026rsquo;s identity. Like showing ID to each other before having a conversation.\nThe infrastructure described here is open source and documented. The patterns apply whether you\u0026rsquo;re running on Oracle\u0026rsquo;s free tier, AWS, Azure, or your own hardware.\n","permalink":"https://jcaldwell-labs.github.io/blog/2026-02-04-ai-infrastructure-explained/","summary":"\u003ch2 id=\"the-invisible-systems-that-run-your-business\"\u003eThe Invisible Systems That Run Your Business\u003c/h2\u003e\n\u003cp\u003eEvery modern business runs on invisible systems.\u003c/p\u003e\n\u003cp\u003eWhen you swipe your badge to enter the building, a system checks your credentials. When you submit an expense report, a system routes it for approval. When you check inventory, a system queries a database somewhere. When a customer places an order, dozens of systems coordinate to make it happen.\u003c/p\u003e\n\u003cp\u003eYou don\u0026rsquo;t think about these systems. They just work. Someone in IT set them up, maintains them, and makes sure they\u0026rsquo;re secure. The systems run in the background while you focus on your actual job.\u003c/p\u003e","title":"The Hidden Infrastructure Behind AI (And Why It Matters for Your Business)"}]